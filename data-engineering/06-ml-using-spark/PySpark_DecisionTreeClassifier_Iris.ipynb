{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "U4Lqkc31PgkF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4Lqkc31PgkF",
    "outputId": "cd96d908-8db4-47f3-d2f2-6be6129b9bac"
   },
   "outputs": [],
   "source": [
    "# Install pyspark and findspark\n",
    "!pip install --ignore-install -q pyspark\n",
    "# Install findspark library\n",
    "!pip install --ignore-install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "FoiOub3qPgpV",
   "metadata": {
    "id": "FoiOub3qPgpV"
   },
   "outputs": [],
   "source": [
    "# Import findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3HzAO31ePgtI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HzAO31ePgtI",
    "outputId": "13cc7d6e-1d2b-4a3e-8af0-888eac294197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 11:57:02) [GCC 12.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.version_info\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77995cdc",
   "metadata": {
    "id": "77995cdc"
   },
   "source": [
    "### 1. Set up spark context and SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d077ba",
   "metadata": {
    "id": "63d077ba"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b8c86d",
   "metadata": {
    "id": "b2b8c86d"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark-DecisitonTreeClassifier_Iris\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e70dff",
   "metadata": {
    "id": "14e70dff"
   },
   "source": [
    "### 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11c16ad",
   "metadata": {
    "id": "e11c16ad"
   },
   "outputs": [],
   "source": [
    "# Load the Iris dataset (assuming you have it in a CSV format)\n",
    "iris_data = spark.read.csv(\"iris-data.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "301ae7cf",
   "metadata": {
    "id": "301ae7cf"
   },
   "outputs": [],
   "source": [
    "# Let's assume that the \"class\" column is our target variable (label)\n",
    "# and the other columns are our features\n",
    "feature_cols = iris_data.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ebb9fd",
   "metadata": {
    "id": "64ebb9fd"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "# Convert string labels into numerical labels\n",
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
    "iris_data = indexer.fit(iris_data).transform(iris_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a10123",
   "metadata": {
    "id": "b7a10123"
   },
   "outputs": [],
   "source": [
    "# Create a feature vector by assembling the feature columns\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "data = assembler.transform(iris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a6f8f0",
   "metadata": {
    "id": "d5a6f8f0"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "(training_data, testing_data) = data.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4415063",
   "metadata": {
    "id": "b4415063"
   },
   "source": [
    "### 3. Create DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68369e5a",
   "metadata": {
    "id": "68369e5a"
   },
   "outputs": [],
   "source": [
    "# Create a DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=5, minInfoGain=0.001, impurity=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc2abb5",
   "metadata": {
    "id": "7bc2abb5"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = dt.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb3b3263",
   "metadata": {
    "id": "eb3b3263"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2063224e",
   "metadata": {
    "id": "2063224e"
   },
   "source": [
    "### 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ddb0265",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ddb0265",
    "outputId": "29cf3222-b66a-478b-e217-24502d3647d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a837404c",
   "metadata": {
    "id": "a837404c"
   },
   "source": [
    "### 4. Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8149a986",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8149a986",
    "outputId": "e083c849-04cd-4449-b532-522771705ece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'sepal length': 0.03\n",
      "Feature 'sepal width': 0.00\n",
      "Feature 'petal length': 0.63\n",
      "Feature 'petal width': 0.34\n"
     ]
    }
   ],
   "source": [
    "feature_importance = model.featureImportances.toArray()\n",
    "\n",
    "# Show feature importance\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f\"Feature '{column}': {feature_importance[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0cba34",
   "metadata": {
    "id": "7f0cba34"
   },
   "source": [
    "### 5. Visualize the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbf812e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbf812e4",
    "outputId": "033d41ec-e514-4634-e4b0-3cad714f89b9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_50e929847c47, depth=4, numNodes=15, numClasses=3, numFeatures=4\n",
      "  If (feature 2 <= 2.45)\n",
      "   Predict: 0.0\n",
      "  Else (feature 2 > 2.45)\n",
      "   If (feature 3 <= 1.75)\n",
      "    If (feature 2 <= 4.95)\n",
      "     If (feature 3 <= 1.65)\n",
      "      Predict: 1.0\n",
      "     Else (feature 3 > 1.65)\n",
      "      Predict: 2.0\n",
      "    Else (feature 2 > 4.95)\n",
      "     If (feature 0 <= 6.35)\n",
      "      Predict: 2.0\n",
      "     Else (feature 0 > 6.35)\n",
      "      Predict: 1.0\n",
      "   Else (feature 3 > 1.75)\n",
      "    If (feature 2 <= 4.85)\n",
      "     If (feature 0 <= 5.95)\n",
      "      Predict: 1.0\n",
      "     Else (feature 0 > 5.95)\n",
      "      Predict: 2.0\n",
      "    Else (feature 2 > 4.85)\n",
      "     Predict: 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7afa755",
   "metadata": {
    "id": "e7afa755",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
